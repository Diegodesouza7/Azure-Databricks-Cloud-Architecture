{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41ce65ed-115c-4f78-a9fd-93525c6c22a1"}}},{"cell_type":"markdown","source":["#![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Key Vault-Backed Secret Scopes\n\n## Learning Objectives\nBy the end of this lessons, you should be able to:\n* Configure Databricks to access Key Vault secrets\n* Read and write data directly from Blob Storage using secrets stored in Key Vault\n* Set different levels of access permission using SAS at the Storage service level\n* Mount Blob Storage into DBFS\n* Describe how mounting impacts secure access to data\n \n### Online Resources\n\n- [Azure Databricks Secrets](https://docs.azuredatabricks.net/user-guide/secrets/index.html)\n- [Azure Key Vault](https://docs.microsoft.com/en-us/azure/key-vault/key-vault-whatis)\n- [Azure Databricks DBFS](https://docs.azuredatabricks.net/user-guide/dbfs-databricks-file-system.html)\n- [Introduction to Azure Blob storage](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction)\n- [Databricks with Azure Blob Storage](https://docs.databricks.com/spark/latest/data-sources/azure/azure-storage.html)\n- [Azure Data Lake Storage Gen1](https://docs.azuredatabricks.net/spark/latest/data-sources/azure/azure-datalake.html#mount-azure-data-lake)\n- [Azure Data Lake Storage Gen2](https://docs.databricks.com/spark/latest/data-sources/azure/azure-datalake-gen2.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e04f21c0-155d-4731-83da-545615a2856e"}}},{"cell_type":"markdown","source":["### Classroom setup\n\nA quick script to define a username variable in Python and Scala."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19d5b863-3f41-4a84-a299-01a9e96dea89"}}},{"cell_type":"code","source":["%run ./Includes/User-Name"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0eb5034f-9862-43b9-b6a0-50820a141c37"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### List Secret Scopes\n\nTo list the existing secret scopes the `dbutils.secrets` utility can be used.\n\nYou can list all scopes currently available in your workspace with:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"43ca6923-b64d-456e-a03f-a58e5a1a3ab8"}}},{"cell_type":"code","source":["%python\ndbutils.secrets.listScopes()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd833039-2a18-4f8a-91d8-35decee8238e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### List Secrets within a specific scope\n\n\nTo list the secrets within a specific scope, you can supply that scope name."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b363573e-9631-4770-8690-a18d43277cfc"}}},{"cell_type":"code","source":["%python\ndbutils.secrets.list(\"demo\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"024100eb-34c0-485e-908a-fbc7761db5bc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Using your Secrets\n\nTo use your secrets, you supply the scope and key to the `get` method.\n\nRun the following cell to retrieve and print a secret."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b3bf6af-dbbb-465f-8c8c-fe6633d214ef"}}},{"cell_type":"code","source":["%python\nprint(dbutils.secrets.get(scope=\"demo\", key=\"storageread\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39425d20-9f8c-4a47-95fd-afebf81d0bb2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Secrets are not displayed in clear text\n\nNotice that the value when printed out is `[REDACTED]`. This is to prevent your secrets from being exposed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc40b206-06ab-4790-9173-d8cc16327e69"}}},{"cell_type":"markdown","source":["## Mount Azure Blob Container - Read/List\n\nIn this section, we'll demonstrating using a `SASTOKEN` that only has list and read permissions managed at the Storage Account level.\n\n**This means:**\n- Any user within the workspace can view and read the files mounted using this key\n- This key can be used to mount any container within the storage account with these privileges"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f54cb646-4599-464c-9cd2-5194e2e3bbca"}}},{"cell_type":"code","source":["# Unmount directory if previously mounted.\nMOUNTPOINT = \"/mnt/commonfiles\"\nif MOUNTPOINT in [mnt.mountPoint for mnt in dbutils.fs.mounts()]:\n  dbutils.fs.unmount(MOUNTPOINT)\n\n# Add the Storage Account, Container, and reference the secret to pass the SAS Token\nSTORAGE_ACCOUNT = dbutils.secrets.get(scope=\"demo\", key=\"storageaccount\")\nCONTAINER = \"commonfiles\"\nSASTOKEN = dbutils.secrets.get(scope=\"demo\", key=\"storageread\")\n\n# Do not change these values\nSOURCE = \"wasbs://{container}@{storage_acct}.blob.core.windows.net/\".format(container=CONTAINER, storage_acct=STORAGE_ACCOUNT)\nURI = \"fs.azure.sas.{container}.{storage_acct}.blob.core.windows.net\".format(container=CONTAINER, storage_acct=STORAGE_ACCOUNT)\n\ntry:\n  dbutils.fs.mount(\n    source=SOURCE,\n    mount_point=MOUNTPOINT,\n    extra_configs={URI:SASTOKEN})\nexcept Exception as e:\n  if \"Directory already mounted\" in str(e):\n    pass # Ignore error if already mounted.\n  else:\n    raise e\n\ndisplay(dbutils.fs.ls(MOUNTPOINT))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e8762f4-8216-4d84-b1a0-bc2ccab32b40"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Define and display a Dataframe that reads a file from the mounted directory"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d54deac8-4bfc-41b0-b833-ecfce3d579f7"}}},{"cell_type":"code","source":["salesDF = (spark.read\n              .option(\"header\", True)\n              .option(\"inferSchema\", True)\n              .csv(MOUNTPOINT + \"/sales.csv\"))\n\ndisplay(salesDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0cea5b3c-b6cb-4630-bf62-f90be021525a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Filter the Dataframe and display the results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e6d2378-4dc2-4e59-9b12-29a350780e9b"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\n\nsales2004DF = (salesDF\n                  .filter((col(\"ShipDateKey\") > 20031231) &\n                          (col(\"ShipDateKey\") <= 20041231)))\ndisplay(sales2004DF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d313100-be35-4f78-94b8-5a0f6db56032"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Details....\n\n\nWhile we can list and read files with this token, our job will abort when we try to write."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f24b0219-8d65-4fd8-b503-798b54ccac93"}}},{"cell_type":"code","source":["try:\n  sales2004DF.write.mode(\"overwrite\").parquet(MOUNTPOINT + \"/sales2004\")\nexcept Exception as e:\n  print(e)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8465831d-a54e-4cd9-ab5e-e3783571f298"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Review\n\nAt this point you should see how to:\n* Use Secrets to access blobstorage\n* Mount the blobstore to dbfs (Data Bricks File System)\n\nMounting data to dbfs makes that content available to anyone in that workspace. \n\nIf you want to access blob store directly without mounting the rest of the notebook demonstrate that process."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef3ad4d5-5b49-44e2-b65d-2de462b1a08d"}}},{"cell_type":"markdown","source":["## Writing Directly to Blob using SAS token\n\nNote that when you mount a directory, by default, all users within the workspace will have the same privileges to interact with that directory. Here, we'll look at using a SAS token to directly write to a blob (without mounting). This ensures that only users with the workspace that have access to the associated key vault will be able to write."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"680a7e2c-1eb0-41da-9731-a7c095e08c25"}}},{"cell_type":"code","source":["spark.conf.set(URI, dbutils.secrets.get(scope=\"demo\", key=\"storagewrite\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca2c6ae1-7cb5-46b5-aec8-8bbb6aa39760"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Listing Directory Contents and writing using SAS token\n\nBecause the configured container SAS gives us full permissions, we can interact with the blob storage using our `dbutils.fs` methods."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8b50878-db9c-4d47-ac71-9a392302920d"}}},{"cell_type":"code","source":["dbutils.fs.ls(SOURCE)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d5e3d6e-8ff2-4a28-9e4b-34f19c82c137"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can write to this blob directly, without exposing this mount to others in our workspace."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a2575e5-e4e8-4dc0-86c1-438309ade28d"}}},{"cell_type":"code","source":["sales2004DF.write.mode(\"overwrite\").parquet(SOURCE + \"/sales2004\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"524028d9-c078-4d90-9f97-49269dae4c68"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.ls(SOURCE)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88de1d65-07aa-4c73-841b-416ffa0b3fb2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Deleting using SAS token\n\nThis scope also has delete permissions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b261787-c34f-4e23-aca7-7b724b297d68"}}},{"cell_type":"code","source":["dbutils.fs.rm(SOURCE + \"/sales2004\", True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8acea6c-24bd-4d51-a5d2-2a0dbedc073e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Cleaning up mounts\n\nIf you don't explicitly unmount, the read-only blob that you mounted at the beginning of this notebook will remain accessible in your workspace."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"faf5f702-013d-4829-9f6f-507fced76a75"}}},{"cell_type":"code","source":["if MOUNTPOINT in [mnt.mountPoint for mnt in dbutils.fs.mounts()]:\n  dbutils.fs.unmount(MOUNTPOINT)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"866470b8-fedc-4241-9980-9f2c8568e08a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Congratulations!\n\nYou should now be able to use the following tools in your workspace:\n\n* Databricks Secrets\n* Azure Key Vault\n* SAS token\n* dbutils.mount"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee889216-7935-40a3-9697-91b18c4fc6e2"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22135150-0fec-4cd4-8c3b-919e8e7d2989"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Key-Vault-Backed-Secret-Scopes","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3243488855258275}},"nbformat":4,"nbformat_minor":0}
